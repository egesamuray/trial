from __future__ import print_function
from typing import NamedTuple
import numpy as np

class RecurrentNetwork(object):
    """
    Class implementing a recurrent network with read-out weights and RLS learning rules.

    **Parameters:**

    * Ni : Number of input neurons
    * N : Number of recurrent neurons
    * No : Number of read-out neurons
    * tau : Time constant of the neurons
    * g : Synaptic strength scaling
    * pc : Connection probability
    * Io : Noise variance
    * delta : Initial value of the P matrix
    * P_plastic : Percentage of neurons receiving plastic synapses
    * dtype: floating point precision (default: np.float32)
    """
    def __init__(self, Ni=2, N=800, No=1, tau=10.0, g=1.5, pc=0.1, Io=0.001, delta=1.0, P_plastic=0.6, dtype=np.float32):
        # Copy the parameters
        self.Ni = Ni
        self.N = N
        self.No = No
        self.tau = tau
        self.g = g
        self.pc = pc
        self.Io = Io
        self.delta = delta
        self.P_plastic = P_plastic
        self.N_plastic = int(self.P_plastic * self.N)  # Number of plastic cells = 480
        self.dtype = dtype

        # Build the network
        self.build()

    def build(self):
        """
        Initializes the network including the weight matrices.
        """
        # Input
        self.I = np.zeros((self.Ni, 1), dtype=self.dtype)

        # Recurrent population
        self.x = np.random.uniform(-1.0, 1.0, (self.N, 1)).astype(self.dtype)
        self.r = np.tanh(self.x).astype(self.dtype)

        # Read-out population
        self.z = np.zeros((self.No, 1), dtype=self.dtype)

        # Weights between the input and recurrent units
        self.W_in = np.random.randn(self.N, self.Ni).astype(self.dtype)

        # Weights between the recurrent units
        self.W_rec = (np.random.randn(self.N, self.N) * self.g / np.sqrt(self.pc * self.N)).astype(self.dtype)

        # The connection pattern is sparse with p=0.1
        connectivity_mask = np.random.binomial(1, self.pc, (self.N, self.N))
        connectivity_mask[np.diag_indices(self.N)] = 0
        self.W_rec *= connectivity_mask

        # Store the pre-synaptic neurons to each plastic neuron
        self.W_plastic = [list(np.nonzero(connectivity_mask[i, :])[0]) for i in range(self.N_plastic)]

        # Inverse correlation matrix of inputs for learning recurrent weights
        self.P = [1. / self.delta * np.identity(len(self.W_plastic[i])).astype(self.dtype) for i in range(self.N_plastic)]

        # Output weights
        self.W_out = (np.random.randn(self.No, self.N) / np.sqrt(self.N)).astype(self.dtype)

        # Inverse correlation matrix of inputs for learning readout weights
        self.P_out = [1. / self.delta * np.identity(self.N).astype(self.dtype) for i in range(self.No)]

    def simulate(self, stimulus, noise=True, trajectory=np.array([]), learn_start=-1, learn_stop=-1, learn_readout=False, verbose=True):
        """
        Simulates the recurrent network for the given duration, with or without plasticity.

        * `stimulus`: np.array for the inputs. Determines the duration.
        * `noise`: if noise should be added to the recurrent units (default: True)
        * `trajectory`: during learning, defines which target function should be learned (default: no learning)
        * `learn_start`: time when learning should start.
        * `learn_stop`: time when learning should stop.
        * `learn_readout`: defines whether the recurrent (False) or readout (True) weights should be learned.
        * `verbose`: defines if the loss should be printed (default: True)
        """

        # Get the stimulus shape to know the duration
        duration, _, _ = stimulus.shape

        # Arrays for recording
        record_r = np.zeros((duration, self.N, 1), dtype=self.dtype)
        record_z = np.zeros((duration, self.No, 1), dtype=self.dtype)

        # Reset the recurrent population
        self.x = np.random.uniform(-1.0, 1.0, (self.N, 1)).astype(self.dtype)
        self.r = np.tanh(self.x).astype(self.dtype)

        # Reset loss term
        self.loss = 0.0

        # Ensure the floating point precision
        stimulus = stimulus.astype(self.dtype)
        trajectory = trajectory.astype(self.dtype)

        # Simulate for the desired duration
        for t in range(duration):

            # Update the neurons' firing rates
            self.update_neurons(stimulus[t, :, :], noise)

            # Recording
            record_r[t, :, :] = self.r
            record_z[t, :, :] = self.z

            # Learning
            if trajectory.size > 0 and t >= learn_start and t < learn_stop and t % 2 == 0:
                if not learn_readout:
                    self.rls_recurrent(trajectory[t, :, :])
                else:
                    self.rls_readout(trajectory[t, :, :])

        # Print the loss at the end of the trial
        if trajectory.size > 0 and verbose:
            print('\tLoss:', self.loss / (learn_stop - learn_start) * 2.)

        return record_r, record_z

    def update_neurons(self, stimulus, noise):
        """
        Updates neural variables for a single simulation step.
        """
        # Inputs are set externally
        self.I = stimulus
        # Noise can be shut off
        I_noise = (self.Io * np.random.randn(self.N, 1) if noise else np.zeros((self.N, 1))).astype(self.dtype)
        # tau * dx/dt + x = I + sum(r) + I_noise
        self.x += (np.dot(self.W_in, self.I) + np.dot(self.W_rec, self.r) + I_noise - self.x) / self.tau
        # r = tanh(x)
        self.r = np.tanh(self.x)
        # z = sum(r)
        self.z = np.dot(self.W_out, self.r)

    def rls_recurrent(self, target):
        """
        Applies the RLS learning rule to the recurrent weights.
        """
        # Compute the error of the recurrent neurons
        error = self.r - target
        self.loss += np.mean(error**2)

        # Apply the FORCE learning rule to the recurrent weights
        for i in range(self.N_plastic):  # for each plastic post neuron
            # Get the rates from the plastic synapses only
            r_plastic = self.r[self.W_plastic[i]]
            # Multiply with the inverse correlation matrix P*R
            PxR = np.dot(self.P[i], r_plastic)
            # Normalization term 1 + R'*P*R
            RxPxR = (1. + np.dot(r_plastic.T, PxR))
            # Update the inverse correlation matrix P <- P - ((P*R)*(P*R)')/(1+R'*P*R)
            self.P[i] -= np.dot(PxR, PxR.T) / RxPxR
            # Learning rule W <- W - e * (P*R)/(1+R'*P*R)
            self.W_rec[i, self.W_plastic[i]] -= error[i, 0] * (PxR / RxPxR)[:, 0]

    def rls_readout(self, target):
        """
        Applies the RLS learning rule to the readout weights.
        """
        # Compute the error of the output neurons
        error = self.z - target
        self.loss += np.mean(error**2)

        # Apply the FORCE learning rule to the readout weights
        for i in range(self.No):  # for each readout neuron
            # Multiply the rates with the inverse correlation matrix P*R
            PxR = np.dot(self.P_out[i], self.r)
            # Normalization term 1 + R'*P*R
            RxPxR = (1. + np.dot(self.r.T, PxR))
            # Update the inverse correlation matrix P <- P - ((P*R)*(P*R)')/(1+R'*P*R)
            self.P_out[i] -= np.dot(PxR, PxR.T) / RxPxR
            # Learning rule W <- W - e * (P*R)/(1+R'*P*R)
            self.W_out[i, :] -= error[i, 0] * (PxR / RxPxR)[:, 0]

        
    def save(self, filename):
        """
        Saves the network into a .npz file.
        """
    # Save the network parameters and weights
        np.savez(
            filename,
            Ni=self.Ni,
            N =self.N,
            No=self.No,
            tau=self.tau,
            g=self.g,
            pc=self.pc,
            Io=self.Io,
            delta=self.delta,
            P_plastic=self.P_plastic,
            W_in=self.W_in,
            W_rec=self.W_rec,
            W_out=self.W_out,
            W_plastic=self.W_plastic
        )
    # Save the list of arrays P separately
        for i, p in enumerate(self.P):
            np.save(f'{filename}_P_{i}.npy', p)
    # Save the list of arrays P_out separately
        for i, p_out in enumerate(self.P_out):
            np.save(f'{filename}_P_out_{i}.npy', p_out)
    
    def load(self, filename):
        """
        Loads the network from a .npz file.
        """
        # Load the network parameters and weights
        data = np.load(filename + '.npz')
        self.Ni = data['Ni']
        self.N = data['N']
        self.No = data['No']
        self.tau = data['tau']
        self.g = data['g']
        self.pc = data['pc']
        self.Io = data['Io']
        self.delta = data['delta']
        self.P_plastic = data['P_plastic']
        self.W_in = data['W_in']
        self.W_rec = data['W_rec']
        self.W_out = data['W_out']
        self.W_plastic = data['W_plastic']

        # Load the list of arrays P separately
        self.P = [np.load(f'{filename}_P_{i}.npy') for i in range(len(self.W_plastic))]
        # Load the list of arrays P_out separately
        self.P_out = [np.load(f'{filename}_P_out_{i}.npy') for i in range(self.No)]       
              
